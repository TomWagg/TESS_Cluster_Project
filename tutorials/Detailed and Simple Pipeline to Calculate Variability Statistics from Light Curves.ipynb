{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.table import Table, join, MaskedColumn, vstack\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import scipy\n",
    "from astropy.time import Time\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from math import e\n",
    "from math import pi\n",
    "from astropy.table import Column\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import math\n",
    "from numpy import exp\n",
    "from scipy import integrate\n",
    "from scipy.integrate import quad\n",
    "import pdb\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.optimize as opt\n",
    "import statsmodels \n",
    "from multiprocessing import Pool\n",
    "from scipy.signal import find_peaks\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import glob\n",
    "import lightkurve as lk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "import glob\n",
    "import lightkurve as lk\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.timeseries import LombScargle\n",
    "from astropy.table import Table\n",
    "import imageio\n",
    "from lightkurve.correctors import RegressionCorrector\n",
    "from lightkurve.correctors import DesignMatrix\n",
    "import scipy.linalg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import gc\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Variability Metrics from Light Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will detail the pipline I made to calculate a slew of variabilty metrics for ensemble light curves of star clusters.\n",
    "\n",
    "Each metric is assigned it's own function, and thus can be called in from the .py file associated with this tutorial. While each function is designed to be run on its own, there will be a compilation function at the end which will calculate all metrics, and make a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need the path we want to save the table of metrics to, as well as the path the already made light curves are located\n",
    "\n",
    "I am going to use the following paths throughout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_to_Save_to= '/Users/Tobin/Dropbox/TESS_project/Variability_Statistics/Test_Pipeline_Module/Variabilty_Stats/'\n",
    "\n",
    "Path_to_Read_in_LCs = '/Users/Tobin/Dropbox/TESS_project/Variability_Statistics/Test_Pipeline_Module/Corrected_LCs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The First thing we are going to do is see if the Light Curve actually exists in our Path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Have_Lightcurve(Cluster_name):\n",
    "    if os.path.exists(Path_to_Read_in_LCs+str(Cluster_name)+'.fits'): \n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the light curve exists, we are going to download it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_in_Lightcurve(Cluster_name):\n",
    "    Corrected_LC=Table.read(Path_to_Read_in_LCs+str(Cluster_name)+'.fits')\n",
    "\n",
    "    return Corrected_LC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Functions to do Nececary Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flux_to_mag(flux):\n",
    "    m1=10    \n",
    "    f1=15000    \n",
    "    mag=2.5*(np.log10(f1/flux)) + m1    \n",
    "    return mag\n",
    "\n",
    "def flux_err_to_mag_err(flux, flux_err):\n",
    "    d_mag_d_flux= -2.5/(flux*np.log(10))\n",
    "\n",
    "    m_err_squared=(abs(d_mag_d_flux)**2)*(flux_err**2)\n",
    "\n",
    "    return np.sqrt(m_err_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variability Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mathmatical expressions, an explanations, for many of these metrics can be found here:\n",
    "https://ui.adsabs.harvard.edu/abs/2017MNRAS.464..274S "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first section is dedicated to statisics that are numeric, or can be boiled down to a single number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rms(flux):\n",
    "    flux_l=list(flux)\n",
    "    squared_fluxes=[]\n",
    "    for i in range(len(flux_l)):\n",
    "        squared_fluxes.append((flux_l[i]**2))\n",
    "    mean=(np.sum(squared_fluxes)/len(squared_fluxes))\n",
    "    root=np.sqrt(mean)\n",
    "\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std(flux):\n",
    "    sd=np.std(flux)\n",
    "    return sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MAD(flux):\n",
    "    flux_l=list(flux)\n",
    "    median=np.median(flux_l)\n",
    "    deviation=abs(flux_l-median)\n",
    "    sum_deviation=np.sum(deviation)\n",
    "    med_of_devs= np.median(deviation)\n",
    "\n",
    "    return med_of_devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generalized to get the range for whatever percentile the heart desires\n",
    "def get_range(flux, bottom_percentile, upper_percentile):\n",
    "    flux_l=list(flux)    \n",
    "    flux_l.sort()    \n",
    "\n",
    "    bottom_ind=int(len(flux_l)*bottom_percentile)\n",
    "    upper_ind=int(len(flux_l)*upper_percentile)\n",
    "\n",
    "    new=flux_l[bottom_ind:upper_ind]\n",
    "    r= new[-1]-new[0]\n",
    "\n",
    "    return r  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness(flux):\n",
    "    sn=scipy.stats.moment(flux, moment=3)\n",
    "    return sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Von_Neumann_Ratio(flux):\n",
    "\n",
    "    num=[]\n",
    "    denom=[]\n",
    "    for i in range(len(flux)-1):\n",
    "        num.append((flux[i+1] - flux[i])**2/(len(flux)-1))\n",
    "    for i in range(len(flux)):    \n",
    "        denom= np.sum((flux[i] - np.mean(flux))**2/(len(flux)-1))\n",
    "\n",
    "    num_=np.sum(num)\n",
    "    denom_=np.sum(denom)\n",
    "    nu= num_/denom_\n",
    "\n",
    "    return 1/nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_J_Stetson_Stat(light_curve):\n",
    "    #convert to mag\n",
    "    mags=light_curve['mag']\n",
    "\n",
    "    mags_err=light_curve['mag_err']\n",
    "\n",
    "    delta_times=[]\n",
    "    for i in range(len(light_curve)-1):\n",
    "        delta_times.append(light_curve['time'][i+1]-light_curve['time'][i])\n",
    "    delta_times.append(1)\n",
    "\n",
    "    light_curve.add_column(Column(delta_times), name=('Delta_Time'), index=4) \n",
    "    mean_mag = np.mean(mags)\n",
    "    n= len(light_curve)\n",
    "\n",
    "    delta= np.array(sqrt(n/ (n-1)) * ((mags - mean_mag)/mags_err))\n",
    "\n",
    "    P=[]\n",
    "    w=[]\n",
    "    for i in range(len(light_curve)):\n",
    "        if light_curve['Delta_Time'][i] < .021:\n",
    "            P.append(delta[i]*delta[i+1])\n",
    "            w.append(1)\n",
    "        else:\n",
    "            P.append(delta[i]**2 -1)\n",
    "            w.append(0.25)\n",
    "\n",
    "    sign=[]\n",
    "    for i in range(len(P)):\n",
    "        sign.append(math.copysign(1, P[i]))\n",
    "\n",
    "    individual_J = []\n",
    "    for i in range(len(P)):\n",
    "        individual_J.append(w[i]*sign[i]*sqrt(abs(P[i])))\n",
    "\n",
    "    J= np.sum(individual_J)/np.sum(w)\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next section are metrics which involve plots and are more complex. The output of these algorithms can\n",
    "themselves be quantified â€” e.g., the number, strength, and frequency of peaks in the LSP, as\n",
    "well as the ratio of power in different frequency ranges (VanderPlas et al. 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LSP(light_curve, Cluster_name, print_figs, save_figs):\n",
    "\n",
    "    def MonteCarlo_LSP(light_curve):\n",
    "\n",
    "        def trial(light_curve):\n",
    "\n",
    "            t = list(light_curve['time'])\n",
    "            dy = light_curve['flux_err']\n",
    "\n",
    "            new_f_val=[]\n",
    "            for i in range(len(light_curve)):\n",
    "                spread=np.random.normal(0, light_curve['flux_err'][i])\n",
    "                new_f_val.append(light_curve['flux'][i] + spread)\n",
    "\n",
    "            omega=np.arange(0.04,11,0.001)\n",
    "            P_LS = LombScargle(t, new_f_val, dy=dy).power(omega)\n",
    "\n",
    "            t=Table([omega, P_LS], names=('Frequency', 'Power'))\n",
    "\n",
    "            return t\n",
    "\n",
    "        #Here I do a Bootstrap resampling incorporating the flux error to get a confidence interval about the LSP\n",
    "        def thousand_trials(light_curve):\n",
    "            list_t=[trial(light_curve) for i in range(1000)]\n",
    "            \n",
    "            omega=np.arange(0.04,11,0.001)\n",
    "\n",
    "            power_array=np.zeros((len(list_t), len(omega)))\n",
    "            for i in range(len(list_t)):\n",
    "                for j in range(len(omega)):\n",
    "                    power_array[i][j]=list_t[i]['Power'][j]\n",
    "\n",
    "            med=np.median(power_array, axis=0)\n",
    "            p16=np.percentile(power_array, 16, axis=0)\n",
    "            p84=np.percentile(power_array, 84, axis=0)\n",
    "\n",
    "            table=Table([omega, p16, med, p84], names=('Frequency', 'Power_16','Power_50', 'Power_84'))\n",
    "\n",
    "            return table\n",
    "\n",
    "        mc_table=thousand_trials(light_curve) #Perform a Bootstrap like Monte Carlo experiment to get confidence interal\n",
    "\n",
    "        mean=np.mean(mc_table['Power_50'])\n",
    "        two_sigma=2*np.std(mc_table['Power_50'])\n",
    "        thresh=mean+two_sigma #Arbitrary definition as to what we are calling a significant peak in the LSP   \n",
    "        peak_ind, pap = find_peaks(mc_table['Power_16'], height=float(thresh)) #Finding the Peaks \n",
    "\n",
    "        fig=plt.figure()\n",
    "        plt.title(\"LS Periodigram\"+str(Cluster_name))\n",
    "        plt.plot(mc_table['Frequency'], mc_table['Power_16'], linestyle='--', color='k', linewidth=.5)\n",
    "        plt.plot(mc_table['Frequency'], mc_table['Power_84'], linestyle='--', color='k', linewidth=.5)\n",
    "        plt.fill_between(mc_table['Frequency'],  mc_table['Power_16'],  mc_table['Power_84'], color='grey', label='$1 \\sigma$ Confidence')\n",
    "        plt.plot(mc_table['Frequency'], mc_table['Power_50'], linestyle='--', color='b', linewidth=1.25, label='Median')\n",
    "        plt.vlines(x=mc_table['Frequency'][peak_ind], ymin=[0 for i in range(len(pap.get('peak_heights')))], \n",
    "                   ymax=pap.get('peak_heights'), linestyle='--', color='g', linewidth=1.25, label='16P > mean+2*sd')\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Frequency [1/Days]')\n",
    "        plt.ylabel('Power')\n",
    "        plt.legend()\n",
    "\n",
    "        path=\"Figures/\" #Sub Folders in the Path\n",
    "        which_fig=\"_LSP\"\n",
    "        out=\".png\"\n",
    "\n",
    "        if save_figs:\n",
    "            plt.savefig(Path_to_Save_to+path+str(Cluster_name)+which_fig+out, format='png') \n",
    "        if print_figs:\n",
    "            plt.show()\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "        n_peaks=len(mc_table[peak_ind])\n",
    "\n",
    "        # 5 Days is around the middle of our time scale, and represents a threshold of how different stars varry (McQuillan et al. 2012)\n",
    "        # So we want to calculate how much of our power is coming from time scales shorter/longer than 5 days\n",
    "        average_power_below_5_days=np.mean(mc_table['Power_50'][:495])\n",
    "        average_power_above_5_days=np.mean(mc_table['Power_50'][495:])\n",
    "\n",
    "        ratio_of_power_at_high_v_low_freq=round(average_power_above_5_days/average_power_below_5_days,5) \n",
    "\n",
    "        # Because each cluster is going to have a different number of peaks, I have an array of len 25, \n",
    "        # we will show the number of peaks wach cluster has as a key to how many indices of the array are relevant\n",
    "        freqs=np.zeros((25))\n",
    "        pap_a=np.zeros((25))\n",
    "        for i in range(len(mc_table[peak_ind])):\n",
    "            freqs[i]=round(mc_table['Frequency'][peak_ind][i],3)\n",
    "            pap_a[i]=round(pap.get('peak_heights')[i], 4)\n",
    "\n",
    "        max_LS_power=max(mc_table['Power_50'])\n",
    "        famp=mc_table['Frequency'][np.where(mc_table['Power_50']==max_LS_power)]\n",
    "\n",
    "        freqs_with_peaks=freqs[np.where( freqs != 0 )]\n",
    "\n",
    "        pixel_loc_write=[]\n",
    "        P_LS_pixel=[]\n",
    "        omega=np.arange(0.04,11,0.001)\n",
    "\n",
    "        return fig, (np.array([round(max_LS_power,5), round(famp[0],4), freqs, pap_a, n_peaks, ratio_of_power_at_high_v_low_freq]))\n",
    "\n",
    "    figure, array= MonteCarlo_LSP(light_curve)\n",
    "\n",
    "    return figure, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr(light_curve, Cluster_name, print_figs, save_figs):\n",
    "\n",
    "    # Becasue the gap in the middle of the observation can drastically effect the ACF, we only calculate the first have \n",
    "    fh_cor_lc=light_curve[:(len(light_curve)//2)]\n",
    "\n",
    "    acf=statsmodels.tsa.stattools.acf(fh_cor_lc['flux'], nlags=len(fh_cor_lc)-1, alpha=.33)\n",
    "\n",
    "    err=acf[1]\n",
    "    ac=acf[0]\n",
    "    acf_p16=[err[i][0] for i in range(len(err))]\n",
    "    acf_p84=[err[i][1] for i in range(len(err))]\n",
    "\n",
    "    deltatimes=[]\n",
    "    for i in range(len(fh_cor_lc)-1):\n",
    "        deltatimes.append(fh_cor_lc['time'][i+1]-fh_cor_lc['time'][i])\n",
    "\n",
    "    plot_times=np.cumsum(deltatimes)\n",
    "\n",
    "    fig=plt.figure()\n",
    "    plt.title(\"ACF\"+str(Cluster_name))\n",
    "    plt.plot(plot_times, ac[:-1])\n",
    "    plt.fill_between(plot_times, acf_p16[:-1], acf_p84[:-1], color='grey', label='$1 \\sigma$ Confidence', alpha=.5)\n",
    "    plt.xlabel('Delta Time [Days]')\n",
    "    plt.text(1, .9, str(Cluster_name), fontsize=16)\n",
    "    path=\"Figures/\"\n",
    "    which_fig=\"_ACF_firsthalf\"\n",
    "    out=\".png\"\n",
    "\n",
    "    if save_figs:\n",
    "        plt.savefig(Path_to_Save_to+path+str(Cluster_name)+which_fig+out, format='png')     \n",
    "    if print_figs:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close(fig) \n",
    "\n",
    "    first_min_ts=plot_times[argrelextrema(ac, np.less)[0][0]]\n",
    "    ac_ai=ac[np.where(plot_times > first_min_ts)]\n",
    "    max_ac=max(ac_ai)\n",
    "    pa_mac=plot_times[np.where(ac==max_ac)]\n",
    "    ac_rms= get_rms(ac)\n",
    "\n",
    "    return fig, (round(max_ac,5), round(pa_mac[0],4), round(ac_rms,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Variable_Stats_Table(Cluster_name, print_figs=True, save_figs=True):   \n",
    "    #Test to see if I have already downloaded and corrected this cluster, If I have, read in the data\n",
    "        if Have_Lightcurve(Cluster_name) == True:\n",
    "            data= Table.read(Path_to_Read_in_LCs+str(Cluster_name)+'.fits')\n",
    "            \n",
    "            normalized_flux=np.array(data['flux'])/np.median(data['flux'])\n",
    "\n",
    "            rms=[np.log10(get_rms(normalized_flux))]\n",
    "            std=[np.log10(get_std(normalized_flux))]\n",
    "            MAD=[np.log10(get_MAD(normalized_flux))]\n",
    "            range_5_95=[np.log10(get_range(normalized_flux, .05, .95))]\n",
    "            range_1_99=[np.log10(get_range(normalized_flux, .01, .99))]\n",
    "\n",
    "            j_stat=[get_J_Stetson_Stat(data)]\n",
    "            sness=[np.log10(abs(skewness(data['flux'])))]\n",
    "            vnr=[Von_Neumann_Ratio(normalized_flux)]\n",
    "\n",
    "            max_ac=[]\n",
    "            period_amac=[]\n",
    "            ac_rms=[]\n",
    "            max_LS_power=[]\n",
    "            freq_amlp=[]\n",
    "            LS_peak_freq=[]\n",
    "            LS_peak_power=[]\n",
    "            LS_n_peaks=[]\n",
    "            LS_ratio=[]\n",
    "\n",
    "            ac_fig, ac_arr= autocorr(data, Cluster_name, print_figs, save_figs)\n",
    "            LS_fig, LS_arr= get_LSP(data, Cluster_name, print_figs, save_figs)\n",
    "\n",
    "            max_ac.append(ac_arr[0])\n",
    "            period_amac.append(ac_arr[1])\n",
    "            ac_rms.append(ac_arr[2])\n",
    "            max_LS_power.append(LS_arr[0])\n",
    "            freq_amlp.append(LS_arr[1])\n",
    "            LS_peak_freq.append(LS_arr[2])\n",
    "            LS_peak_power.append(LS_arr[3])\n",
    "            LS_n_peaks.append(LS_arr[4])\n",
    "            LS_ratio.append(LS_arr[5])\n",
    "\n",
    "            name___=[Cluster_name]\n",
    "\n",
    "\n",
    "            Simple_Stats_Table=Table((name___, rms, std, range_5_95, range_1_99, MAD, j_stat, vnr, sness,\n",
    "                                      max_ac, period_amac, ac_rms, max_LS_power, freq_amlp, LS_peak_freq, LS_peak_power, \n",
    "                                      LS_n_peaks, LS_ratio), \n",
    "                                      names=('Cluster', 'RMS', 'STD', '5-95_Range', '1-99_Range', \n",
    "                                             'MAD', 'Stetson_J_stat', 'Von_Neumann_Ratio', 'Skewness', 'Max_AutoCorr', 'AutoCorr_Period_atM','AutoCorr_rms', \n",
    "                                             'Max_LS_Power', 'LS_Freq_atM', 'LS_Peak_Freq','LS_Peak_Power', 'N_LS_Peaks',\n",
    "                                             'LS_Ratio'))\n",
    "            \n",
    "            #Writing out the table\n",
    "            Simple_Stats_Table.write(Path_to_Save_to+'Stats_Tables/'+str(Cluster_name)+'stats_table.fits', overwrite=True)\n",
    "  \n",
    "            return Simple_Stats_Table\n",
    "        \n",
    "        else: #This statement means that the lightcuve does not exist in our path\n",
    "            name___= [Cluster_name]\n",
    "\n",
    "            std=np.ma.array([0], mask=[1])\n",
    "            rms=np.ma.array([0], mask=[1])\n",
    "            range_5_95=np.ma.array([0], mask=[1])\n",
    "            range_1_99=np.ma.array([0], mask=[1])\n",
    "            MAD=np.ma.array([0], mask=[1])\n",
    "            j_stat=np.ma.array([0], mask=[1])\n",
    "            vnr=np.ma.array([0], mask=[1])\n",
    "            sness=np.ma.array([0], mask=[1])\n",
    "            max_ac=np.ma.array([0], mask=[1])\n",
    "            period_amac=np.ma.array([0], mask=[1])\n",
    "            ac_rms=np.ma.array([0], mask=[1])\n",
    "            max_LS_power=np.ma.array([0], mask=[1])\n",
    "            freq_amlp=np.ma.array([0], mask=[1])\n",
    "            LS_peak_freq=[np.zeros(25)]\n",
    "            LS_peak_power=[np.zeros(25)]\n",
    "            LS_n_peaks=np.ma.array([0], mask=[1])\n",
    "            LS_ratio=np.ma.array([0], mask=[1])\n",
    "\n",
    "            Simple_Stats_Table=Table((name___, rms, std, range_5_95, range_1_99, MAD, j_stat, vnr, sness,\n",
    "                                      max_ac, period_amac, ac_rms, max_LS_power, freq_amlp, LS_peak_freq, LS_peak_power, \n",
    "                                      LS_n_peaks, LS_ratio), \n",
    "                                      names=('Cluster', 'RMS', 'STD', '5-95_Range', '1-99_Range', \n",
    "                                             'MAD', 'Stetson_J_stat', 'Von_Neumann_Ratio', 'Skewness', 'Max_AutoCorr', 'AutoCorr_Period_atM','AutoCorr_rms', \n",
    "                                             'Max_LS_Power', 'LS_Freq_atM', 'LS_Peak_Freq','LS_Peak_Power', 'N_LS_Peaks', \n",
    "                                             'LS_Ratio')) \n",
    "            \n",
    "            #Writing out the table\n",
    "            Simple_Stats_Table.write(Path_to_Save_to+'Stats_Tables/'+str(Cluster_name)+'stats_table.fits', overwrite=True) \n",
    "       \n",
    "            return Simple_Stats_Table\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
